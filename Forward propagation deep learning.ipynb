{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Neural Networks:\n",
    "## Forward Propagation\n",
    "\n",
    "A brief introduction to programming forward propagation in deep learning neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "To keep things simple, we consider only two input features. We have one hidden layer that captures the interaction of the two inputs. The hidden layer has two nodes. See the diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"deep2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how we execute this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer values: [5 1]\n",
      "Output value: 9\n"
     ]
    }
   ],
   "source": [
    "#Define the input data as an array\n",
    "input_data=np.array([2,3])\n",
    "\n",
    "#Define the weights as arrays. Each node has an array associated with it. The value the node takes is determined by\n",
    "#the dot product of the node's weight with the input data\n",
    "weights={\"node_0\":np.array([1,1]),\"node_1\":np.array([-1,1]),\"output\":np.array([2,-1])}\n",
    "\n",
    "#Compute the hidden layer node values using matrix multiplication (dot product)\n",
    "node_0_value=np.dot(input_data,weights[\"node_0\"])\n",
    "node_1_value=np.dot(input_data,weights[\"node_1\"])\n",
    "\n",
    "#Since the values of the nodes in the hidden layer are the input values for the output node,\n",
    "#we define a hidden layer array using the node values, then multiply by the output's weight array\n",
    "hidden_layer_1=np.array([node_0_value,node_1_value])\n",
    "output_value=np.dot(hidden_layer_1,weights[\"output\"])\n",
    "\n",
    "print(\"Hidden layer values: {}\".format(hidden_layer_1))\n",
    "print(\"Output value: {}\".format(output_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "To allow non linear interactions, we introduce an activation function at each node. The linear transformation at each node, as described above, becomes the input of the activation function, and the output becomes the node's value. The default industry standard activation function is the ReLU function g: g(z)=max{0,z}. In other words, the ReLU function outputs zero if the input is negative, and outputs the input if it is positive.\n",
    "\n",
    "The following block of code illustrates how we use an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer values: [5 1]\n",
      "Output value: 9\n"
     ]
    }
   ],
   "source": [
    "def relu(val):\n",
    "    return max(0,val)\n",
    "\n",
    "input_data=np.array([2,3])\n",
    "\n",
    "weights={\"node_0\":np.array([1,1]),\"node_1\":np.array([-1,1]),\"output\":np.array([2,-1])}\n",
    "\n",
    "#Compute the hidden layer node values using matrix multiplication (dot product). The result of the linear transformation\n",
    "#becomes the input for the activation function. The output of the activation function becomes the node value.\n",
    "node_0_input=np.dot(input_data,weights[\"node_0\"])\n",
    "node_1_input=np.dot(input_data,weights[\"node_1\"])\n",
    "\n",
    "node_0_output=relu(node_0_input)\n",
    "node_1_output=relu(node_1_input)\n",
    "\n",
    "hidden_layer_1=np.array([node_0_output,node_1_output])\n",
    "output_value=np.dot(hidden_layer_1,weights[\"output\"])\n",
    "\n",
    "print(\"Hidden layer values: {}\".format(hidden_layer_1))\n",
    "print(\"Output value: {}\".format(output_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple inputs\n",
    "\n",
    "Let's modify our code to take multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 17])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a vectorized version of relu\n",
    "relu_vect=np.vectorize(relu)\n",
    "\n",
    "input_matrix=np.array([[2,3],[4,5]])\n",
    "\n",
    "weights={\"node_0\":np.array([1,1]),\"node_1\":np.array([-1,1]),\"output\":np.array([2,-1])}\n",
    "\n",
    "node_0_input=np.dot(input_matrix,weights[\"node_0\"])\n",
    "node_0_output=relu_vect(node_0_input)\n",
    "node_0_output=node_0_output.reshape(2,1)\n",
    "\n",
    "node_1_input=np.dot(input_matrix,weights[\"node_1\"])\n",
    "node_1_output=relu_vect(node_1_input)\n",
    "node_1_output=node_1_output.reshape(2,1)\n",
    "\n",
    "hidden_layer1=np.concatenate((node_0_output,node_1_output),axis=1)\n",
    "\n",
    "output=np.dot(hidden_layer1,weights[\"output\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Hidden Layers\n",
    "\n",
    "Let's create deep learning prediction function. The function should take two inputs: an input matrix, where the rows are values for the input; and a layers list. The list should contain lists, where each list is a list of weights of a layer. The function will iterate through the layers list, so the first list in the layers should correspond to the first layer, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learn_predict(layers,input_mat):\n",
    "    input_matrix=input_mat.copy()\n",
    "    for weight_list in layers:\n",
    "        node_matrix_list=[]\n",
    "        for weight in weight_list:\n",
    "            node_input=np.dot(input_matrix,weight)\n",
    "            node_output=relu_vect(node_input)\n",
    "            node_output=node_output.reshape(2,1)\n",
    "            node_matrix_list.append(node_output)\n",
    "        input_matrix=node_matrix_list[0]\n",
    "        for node_matrix in node_matrix_list[1:]:\n",
    "            input_matrix=np.concatenate((input_matrix,node_matrix),axis=1)\n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our function. Let's assume the input has two features. Let's create an input matrix that has two data points. Thus, our input matrix should be 2x2, where the rows represent unique data points and the columns represent features. Next, we will create three lists of weights. Each of these lists represent a hidden layer (except the last, which is the output \"layer\"). The first layer should have two weights (two nodes), the second hidden layer should have three weights (three nodes) and the output \"layer\" should have one weight.\n",
    "\n",
    "Notice that the weights of a given layer should be an array of size equal to the number of inputs it receives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"deep4.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix=np.array([[2,3],[4,5]])\n",
    "weight1=[np.array([1,1]),np.array([-1,1])]\n",
    "weight2=[np.array([3,2]),np.array([-3,2]),np.array([1,1])]\n",
    "weight3=[np.array([1,1,3])]\n",
    "layers=[weight1,weight2,weight3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35],\n",
       "       [59]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_learn_predict(weights,input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
