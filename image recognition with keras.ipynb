{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Recognition with Deep Learning with Keras\n",
    "\n",
    "Image recognition of handwritten digits, using the mnist data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mnist\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data set is the mnist sample of 60,000 handwritten digits. Each sample is a 28x28 two dimensional array of pixels. Each value in the array is the pixel value and the position in the array represents the position in the actual 2D space where the digit was written.\n",
    "\n",
    "In our data set, the two dimensional data points are flattened to a one dimensional array of 28x28=784 points. The target set denotes what digit the sample represents, 0-9. Thus, there are ten categories for the target set. Using one-hot-encoding, the target set becomes an array of 10 elements.\n",
    "\n",
    "The test set is designed, specifically, so that none of the images was drawn by any of the drawers used in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=mnist.train.images\n",
    "y_train=mnist.train.labels\n",
    "\n",
    "X_valid=mnist.validation.images\n",
    "y_valid=mnist.validation.labels\n",
    "\n",
    "X_test=mnist.test.images\n",
    "y_test=mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "X_train: (55000, 784)\n",
      "y_train: (55000, 10)\n",
      "X_valid: (5000, 784)\n",
      "y_valid: (5000, 10)\n",
      "X_test: (10000, 784),\n",
      "y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#View the shapes of the data sets\n",
    "print(\"Shapes\")\n",
    "print(\"X_train: {}\\ny_train: {}\\nX_valid: {}\\ny_valid: {}\\nX_test: {},\\ny_test: {}\".format(X_train.shape,\n",
    "                                                                                      y_train.shape,\n",
    "                                                                                      X_valid.shape,\n",
    "                                                                                      y_valid.shape,\n",
    "                                                                                      X_test.shape,\n",
    "                                                                                      y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of Sequential, as our model\n",
    "model1=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two hidden layers with 300 nodes, and an output layer with 10 nodes\n",
    "model1.add(Dense(300,activation=\"relu\",input_shape=(784,)))\n",
    "model1.add(Dense(300,activation=\"relu\"))\n",
    "model1.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an early stopping callback. This will stop the learning if it is not improving. Set the patience to two.\n",
    "#The learning will stop if accuracy hasn't improved two epochs in a row\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor=EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile \n",
    "model1.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 15s 272us/step - loss: 0.2049 - acc: 0.9384\n",
      "Epoch 2/50\n",
      "  416/55000 [..............................] - ETA: 16s - loss: 0.0852 - acc: 0.9663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 15s 264us/step - loss: 0.0871 - acc: 0.9736\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 14s 256us/step - loss: 0.0587 - acc: 0.9807\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 14s 257us/step - loss: 0.0434 - acc: 0.9857\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 14s 253us/step - loss: 0.0348 - acc: 0.9889\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 17s 300us/step - loss: 0.0291 - acc: 0.99061s - loss:\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 16s 296us/step - loss: 0.0265 - acc: 0.9914\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 17s 307us/step - loss: 0.0204 - acc: 0.9930\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 17s 313us/step - loss: 0.0184 - acc: 0.9943\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 23s 411us/step - loss: 0.0180 - acc: 0.9942\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 22s 397us/step - loss: 0.0181 - acc: 0.9947\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 24s 440us/step - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 22s 409us/step - loss: 0.0155 - acc: 0.9951\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 24s 430us/step - loss: 0.0147 - acc: 0.9956\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 22s 409us/step - loss: 0.0140 - acc: 0.9962\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 23s 424us/step - loss: 0.0122 - acc: 0.9962\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 22s 401us/step - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 21s 387us/step - loss: 0.0134 - acc: 0.9965\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 21s 389us/step - loss: 0.0132 - acc: 0.9967\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 21s 388us/step - loss: 0.0088 - acc: 0.9973\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 15s 267us/step - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 14s 257us/step - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 14s 260us/step - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 15s 267us/step - loss: 0.0129 - acc: 0.9967\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 14s 247us/step - loss: 0.0128 - acc: 0.9968\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 14s 248us/step - loss: 0.0098 - acc: 0.99710s - loss: 0.0094 - \n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 14s 253us/step - loss: 0.0091 - acc: 0.9977\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 13s 236us/step - loss: 0.0108 - acc: 0.9972\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 13s 234us/step - loss: 0.0080 - acc: 0.9981\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 14s 263us/step - loss: 0.0082 - acc: 0.9978\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 14s 263us/step - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 14s 263us/step - loss: 0.0080 - acc: 0.9981\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 14s 262us/step - loss: 0.0095 - acc: 0.9978\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 14s 261us/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 14s 263us/step - loss: 0.0131 - acc: 0.9972\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 15s 270us/step - loss: 0.0105 - acc: 0.9979\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 14s 262us/step - loss: 0.0064 - acc: 0.9985\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 15s 272us/step - loss: 0.0107 - acc: 0.9976\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 14s 260us/step - loss: 0.0077 - acc: 0.9984\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 14s 259us/step - loss: 0.0104 - acc: 0.9978\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 13s 244us/step - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 14s 252us/step - loss: 0.0122 - acc: 0.9974\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 14s 253us/step - loss: 0.0070 - acc: 0.9985\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 14s 245us/step - loss: 0.0115 - acc: 0.9978\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 13s 240us/step - loss: 0.0092 - acc: 0.9983\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 13s 230us/step - loss: 0.0087 - acc: 0.9984\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 13s 233us/step - loss: 0.0109 - acc: 0.9980\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 13s 243us/step - loss: 0.0102 - acc: 0.9979\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 13s 239us/step - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 13s 245us/step - loss: 0.0095 - acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ee0c280b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "model1.fit(X_train,y_train,epochs=50,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 4s 64us/step\n",
      "5000/5000 [==============================] - 0s 63us/step\n",
      "Train Accuracy: [0.0025840035264986828, 0.99945454545454548]\n",
      "Validation Accuracy: [0.1864383040974065, 0.98199999999999998]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on train and test sets\n",
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(model1.evaluate(X_train,y_train),\n",
    "                                                    model1.evaluate(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a very accurate model, comparable to industry standards. Let us check the validation accuracy on a model with the same parameters, but trained with fewer epochs. 50 epochs takes about 20 minutes to train on my laptop (which is not a long time for business applications, but is a long time for the sake of practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two hidden layers with 300 nodes, and an output layer with 10 nodes\n",
    "model2.add(Dense(300,activation=\"relu\",input_shape=(784,)))\n",
    "model2.add(Dense(300,activation=\"relu\"))\n",
    "model2.add(Dense(10,activation=\"softmax\"))\n",
    "#Compile \n",
    "model2.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ede3dca58>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model with 20 epochs\n",
    "model2.fit(X_train,y_train,epochs=20,callbacks=[early_stopping_monitor],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 4s 65us/step\n",
      "5000/5000 [==============================] - 0s 69us/step\n",
      "Train Accuracy: [0.0091619150468506879, 0.99752727272727271]\n",
      "Validation Accuracy: [0.12433379970914102, 0.98019999999999996]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model2 on train and test sets\n",
    "print(\"Train Accuracy: {}\\nValidation Accuracy: {}\".format(model2.evaluate(X_train,y_train),\n",
    "                                                    model2.evaluate(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we can half our epochs and still achieve similar accuracy. For the sake of model selection and practice, let's use this lower number of epochs for training.\n",
    "\n",
    "Let's try a couple more models. The first one will be a model with 2 hidden layers of 800 units, and the second will have 3 hidden layers of 300 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ee3641f60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Dense(800,activation=\"relu\",input_shape=(784,)))\n",
    "model3.add(Dense(800,activation=\"relu\"))\n",
    "model3.add(Dense(10,activation=\"softmax\"))\n",
    "#Compile \n",
    "model3.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "#fit the model with 20 epochs\n",
    "model3.fit(X_train,y_train,epochs=20,callbacks=[early_stopping_monitor],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ee35767b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4=Sequential()\n",
    "model4.add(Dense(300,activation=\"relu\",input_shape=(784,)))\n",
    "model4.add(Dense(300,activation=\"relu\"))\n",
    "model4.add(Dense(300,activation=\"relu\"))\n",
    "model4.add(Dense(10,activation=\"softmax\"))\n",
    "#Compile \n",
    "model4.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "#fit the model with 20 epochs\n",
    "model4.fit(X_train,y_train,epochs=20,callbacks=[early_stopping_monitor],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3:\n",
      "Train Accuracy: [0.015142077130134542, 0.9965090909090909]\n",
      "Validation Accuracy: [0.16172480549342036, 0.98160000000000003]\n",
      "\n",
      "\n",
      "Model 4:\n",
      "Train Accuracy: [0.0066458705740710606, 0.99812727272727275]\n",
      "Validation Accuracy: [0.12772725383046699, 0.98019999999999996]\n"
     ]
    }
   ],
   "source": [
    "#Accuracies of models 3 and 4\n",
    "print(\"Model 3:\\nTrain Accuracy: {}\\nValidation Accuracy: {}\".format(model3.evaluate(X_train,y_train,verbose=0),\n",
    "                                                    model3.evaluate(X_valid,y_valid,verbose=0)))\n",
    "print(\"\\n\\nModel 4:\\nTrain Accuracy: {}\\nValidation Accuracy: {}\".format(model4.evaluate(X_train,y_train,verbose=0),\n",
    "                                                    model4.evaluate(X_valid,y_valid,verbose=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not seeing significant improvements with the other models. Assuming all models to be equal, let's choose model 1 to be our model of choice and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 test accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1 test accuracy: {}\".format(model1.evaluate(X_test,y_test,verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our model of two hidden layers of 300 nodes each had a test accuracy of 98%. This is similar to the best results achieved for deep learning models, published in the literature.\n",
    "\n",
    "Increasing layers, nodes, or epochs beyond 20, did not yield substantial increases in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
